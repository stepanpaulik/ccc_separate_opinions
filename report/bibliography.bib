@article{eliasekAutomatickaKlasifikaceVyznamovych2020,
  title = {Automatická Klasifikace Významových Celků v Judikatuře},
  author = {Eliášek, Martin and Kól, Jakub and Švaňa, Miloš},
  date = {2020-06-30},
  journaltitle = {Revue pro právo a technologie},
  shortjournal = {RPT},
  volume = {11},
  number = {21},
  pages = {3--20},
  issn = {1805-2797, 1804-5383},
  doi = {10.5817/RPT2020-1-1},
  url = {https://journals.muni.cz/revue/article/view/12532},
  urldate = {2022-10-15},
  abstract = {Příspěvek popisuje experiment se strojovým učením, kdy na minimálním datasetu bylo pomocí kombinace známých algoritmů strojového učení dosaženo relativně vysoké úspěšnosti klasifikace významových celků. Významovými celky se zde rozumí např. hlavička, procesní historie a argumentace stran.}
}

@article{ludersProportionalityArgumentIdentification2023,
  title = {Proportionality as an Argument: {{Identification}} of a Judicial Decision Technique},
  author = {Lüders, Kilian and Stohlman, Bent},
  date = {2023},
  journaltitle = {DRAFT for 5th ANNUAL COMPTEXT Conference},
  abstract = {Constitutional courts are important and powerful actors in many democracies. In particular, the Ger- man Federal Constitutional Court (GFCC) is internationally known not only for its strength as a national institution but also as the inventor of a now internationally established decision-making tech- nique: the proportionality test. To better understand the behavior of the court beyond its decision outcomes, we use argument mining approaches to classify decisions of the GFCC regarding whether they invoke proportionality or not. Thereby, our paper makes three contributions: Firstly, it critically discusses the understanding of argument in the argument mining literature and introduces proportion- ality as a legal argument technique. Secondly, it presents a new dataset in which proportionality was annotated at the sentence level in 300 decisions. Thirdly, rule-based and machine-learning methods for classifying decisions are tested.}
}

@online{mikolovEfficientEstimationWord2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  date = {2013-09-06},
  eprint = {1301.3781},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1301.3781},
  url = {http://arxiv.org/abs/1301.3781},
  urldate = {2023-08-20},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/stepanpaulik/Zotero/storage/76Y7M5KX/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf;/Users/stepanpaulik/Zotero/storage/J5BKJR3J/1301.html}
}
